# Final Touches

Today in Day 1 we:
- Learned what an API is and how to use the HuggingFace Inference API
- Learned what a transformer is and how they work
- Implemented GPT2-Large using the Inference API
- Dove into documentation to improve performance

Somethings to think about before joining us for Day 2:
- Why is the user interface (UI) important when working with machine learning models?
- What possible ethical considerations are there when implementing large language models?
- How can we use text generation to solve other problems like text summarization?

Continue through this short course to learn more!

## Checkout AI Camp!
<img src="https://i.imgur.com/cm5IS8V.png" width="100px" height="100px" id="ai-camp">

 **If you are a teenager interested in joining a community solving problems with technology and exploring careers in tech, check out AI Camp!**

  We offer 1-week and 3-week camps to start, but exceptional students can join our [Team Tomorrow](https://teamtomorrow.com/). **_TT members work after school + weekends on paid internal and external projects_**, opening doors for their future. 

In fact TT member Shriya Dave, a college freshman, helped create todays content!

A copy of our working code is below:

```python
API_Token = ""

from huggingface_hub.inference_api import InferenceApi

inference = InferenceApi(repo_id="gpt2-large", token=API_Token)

# defining our parameters
top_p_params = {"max_length": 128, "top_p": 0.95, "do_sample": True}
top_k_params = {"max_length": 128, "top_k": 4, "do_sample": True}
contrastive_params = {"max_length": 128, "penalty_alpha": 0.6, "top_k": 4}

input_string = "Learn about AI because"
result = inference(input_string)
print(result)

result = inference(input_string, top_p_params)
print("Top P: {}".format(result))

result = inference(input_string, top_k_params)
print("Top K: {}".format(result))

result = inference(input_string, contrastive_params)
print("Contrastive: {}".format(result))

```